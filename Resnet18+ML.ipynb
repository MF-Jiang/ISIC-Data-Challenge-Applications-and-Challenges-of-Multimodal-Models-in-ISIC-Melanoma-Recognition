{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2d2f15-1bea-47ae-86d4-007bd5c75312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72644578-fbab-42f9-834e-09710f606b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3477/338700035.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_tensor = torch.load(\"./data/loaded_images_tensor.pt\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metadata_df = pd.read_csv(\"./data/sort.csv\")\n",
    "image_tensor = torch.load(\"./data/loaded_images_tensor.pt\")\n",
    "\n",
    "assert len(metadata_df) == image_tensor.size(0), \"数据大小不匹配\"\n",
    "# image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044c529c-7904-4048-9c43-07ea27959f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "metadata_df[['age_approx', 'clin_size_long_diam_mm']] = scaler.fit_transform(metadata_df[['age_approx', 'clin_size_long_diam_mm']])\n",
    "# print(metadata_df)\n",
    "\n",
    "eva_data = metadata_df.drop(columns = ['id', 'isic_id'])\n",
    "\n",
    "# X_metadata =  metadata_df.drop(columns = ['is_melanoma','isic_id'])\n",
    "X_metadata =  metadata_df\n",
    "y = metadata_df['is_melanoma']\n",
    "\n",
    "X_train_meta_V, X_test_meta_V, y_train, y_test = train_test_split(X_metadata, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_meta = X_train_meta_V.drop(columns = ['is_melanoma','isic_id'])\n",
    "X_test_meta = X_test_meta_V.drop(columns = ['is_melanoma','isic_id'])\n",
    "\n",
    "image_ids = X_train_meta['id'].values\n",
    "X_train_meta_tensor = image_tensor[image_ids]\n",
    "X_train_meta =  X_train_meta.drop(columns = ['id'])\n",
    "\n",
    "image_ids_test = X_test_meta['id'].values\n",
    "X_test_meta_tensor = image_tensor[image_ids_test]\n",
    "X_test_meta =  X_test_meta.drop(columns = ['id'])\n",
    "# X_train_meta_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be9cda6-2096-44ad-aaae-ea47eccef0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# X_train_meta_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc18b3bb-c71f-46ad-8013-aff2f69b3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3779, 3, 224, 224])\n",
      "(3779,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_meta_tensor.shape) \n",
    "print(y_train.shape)\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)\n",
    "# X_train_meta_tensor\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b2e1fa-963d-4857-bcd5-17eb0b6b9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TensorDataset(X_train_meta_tensor, y_train)\n",
    "test_dataset = TensorDataset(X_test_meta_tensor, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3379c5-f9ab-4968-abdb-248f5af355c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd7bb7c-9137-4f4a-b58b-978cf54bf139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet18Binary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Binary, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)  \n",
    "        num_features = self.resnet18.fc.in_features  \n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 1),  \n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "class CommonBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):        # 普通Block简单完成两次卷积操作\n",
    "        super(CommonBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x                                            # 普通Block的shortcut为直连，不需要升维下采样\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)       # 完成一次卷积\n",
    "        x = self.bn2(self.conv2(x))                             # 第二次卷积不加relu激活函数\n",
    "\n",
    "        x += identity                                           # 两路相加\n",
    "        return F.relu(x, inplace=True)                          # 添加激活函数输出\n",
    "\n",
    "\n",
    "class SpecialBlock(nn.Module):                                  # 特殊Block完成两次卷积操作，以及一次升维下采样\n",
    "    def __init__(self, in_channel, out_channel, stride):        # 注意这里的stride传入一个数组，shortcut和残差部分stride不同\n",
    "        super(SpecialBlock, self).__init__()\n",
    "        self.change_channel = nn.Sequential(                    # 负责升维下采样的卷积网络change_channel\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride[0], padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.change_channel(x)                       # 调用change_channel对输入修改，为后面相加做变换准备\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))                             # 完成残差部分的卷积\n",
    "\n",
    "        x += identity\n",
    "        return F.relu(x, inplace=True)                          # 输出卷积单元\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, classes_num):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.prepare = nn.Sequential(           # 所有的ResNet共有的预处理==》[batch, 64, 56, 56]\n",
    "            nn.Conv2d(3, 64, 7, 2, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(            # layer1有点特别，由于输入输出的channel均是64，故两个CommonBlock\n",
    "            CommonBlock(64, 64, 1),\n",
    "            CommonBlock(64, 64, 1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(            # layer234类似，由于输入输出的channel不同，故一个SpecialBlock，一个CommonBlock\n",
    "            SpecialBlock(64, 128, [2, 1]),\n",
    "            CommonBlock(128, 128, 1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            SpecialBlock(128, 256, [2, 1]),\n",
    "            CommonBlock(256, 256, 1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            SpecialBlock(256, 512, [2, 1]),\n",
    "            CommonBlock(512, 512, 1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))    # 卷积结束，通过一个自适应均值池化==》 [batch, 512, 1, 1]\n",
    "        self.fc = nn.Sequential(                # 最后用于分类的全连接层，根据需要灵活变化\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, classes_num)         # 这个使用CIFAR10数据集，定为10分类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prepare(x)         # 预处理\n",
    "\n",
    "        x = self.layer1(x)          # 四个卷积单元\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.pool(x)            # 池化\n",
    "        x = x.reshape(x.shape[0], -1)   # 将x展平，输入全连接层\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab906bcb-ad15-4e32-825c-52fa33ef2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18Binary()\n",
    "#model = ResNet18()\n",
    "criterion = nn.BCELoss()  # 二分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b37b5-5b01-4fc9-b894-1fae01b3ff52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_accuracies = []\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换到训练模式\n",
    "    epoch_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        outputs = model(images)  # 前向传播\n",
    "        loss = criterion(outputs.view(-1), labels.float())  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # 计算平均损失并存储\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c3066-9670-47e3-b7db-6bd9c33432e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results = []\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "model.eval()  # 切换到评估模式\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = (outputs.view(-1) > 0.5).float()  # 将输出转为0或1\n",
    "        predicted_results.extend(predicted.cpu().numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float()).sum().item()\n",
    "        all_predictions.extend(predicted.cpu().numpy())  # 收集所有预测值\n",
    "        all_labels.extend(labels.cpu().numpy())         # 收集所有真实标签\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# # 将预测结果转为 DataFrame\n",
    "# predicted_results_df = pd.DataFrame(predicted_results, columns=['Predicted_Feature'])\n",
    "\n",
    "# # 将预测结果作为新特征加入到 X_train_meta_V\n",
    "# X_test_meta_V = pd.concat([X_test_meta_V.reset_index(drop=True), predicted_results_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261c622-3bc7-4370-a139-83957918ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Class 0', 'Class 1'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39307f-eaa0-4977-b123-5343b8e090c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "torch.save(model.state_dict(), 'ResNet18_Binary.pth')\n",
    "print(\"Model saved to ResNet18_Binary.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a126978-393a-468a-b158-8f992a88ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ResNet18_Binary.pth'))\n",
    "model.eval()  # 切换到评估模式\n",
    "print(\"Model loaded from ResNet18_Binary.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bea27-5401-49dc-aa25-fcecc69177c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77372093-e968-4ddc-8b14-7b268511156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2a36a-4a9d-4e2b-922d-13e2639a4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 61), test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Test')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Testing Accuracy over Test Samples')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e168b9b-354b-4217-b0e2-470d8f8f8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dataset = TensorDataset(image_tensor, y)\n",
    "# image_dataset_loader = DataLoader(image_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "features = eva_data.drop(columns=['is_melanoma']).values  # 提取特征\n",
    "labels = eva_data['is_melanoma'].values  # 提取标签（如果有）\n",
    "\n",
    "image_tensor = torch.tensor(image_tensor) if not isinstance(image_tensor, torch.Tensor) else image_tensor\n",
    "y = torch.tensor(y) if not isinstance(y, torch.Tensor) else y\n",
    "\n",
    "# 创建 DataLoader，用于批量处理整个数据集\n",
    "batch_size = 32  # 设置批量大小\n",
    "eva_loader = DataLoader(TensorDataset(image_tensor, y), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 加载模型并切换到评估模式\n",
    "model.load_state_dict(torch.load('Simple ResNet18_Binary.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 存储预测结果\n",
    "predicted_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features_batch, _ in eva_loader:\n",
    "        outputs = model(features_batch)  # 模型预测\n",
    "        predicted = (outputs.view(-1) > 0.5).float()  # 二分类，转为 0 或 1\n",
    "        predicted_results.extend(predicted.cpu().numpy())  # 保存预测结果\n",
    "\n",
    "# 将预测结果转为 Pandas DataFrame\n",
    "eva_data['Predicted_Feature'] = predicted_results  # 添加预测结果为新特征\n",
    "\n",
    "# 打印数据集以检查结果\n",
    "print(eva_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70a68f-9bdb-43f0-a4c9-2d79f3c25449",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ead11e-12f8-4ad7-b3d5-08fcdb6a1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_data.to_csv('./Resnet18_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812c7b6-651b-423d-9ffb-49c8410fb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install catboost\n",
    "%pip install xgboost\n",
    "%pip install seaborn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1182f44-f740-4021-bf96-6dadf7b63e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = eva_data.drop(columns=['is_melanoma'])\n",
    "y = eva_data['is_melanoma']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83dd49-cb18-49b5-98e8-6cb9fb4d7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 提取特征重要性\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X.columns\n",
    "\n",
    "# 可视化特征重要性\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[indices], y=features[indices])\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2533216-9186-4efb-bf77-b310f94727bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "rf_preds = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edb4bd-d761-441b-bb23-2e2548f553d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]  # 获取概率\n",
    "fpr, tpr, _ = roc_curve(y_test, rf_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb7a05-f235-4dcc-861c-f2a90e0684b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d407bd3-4789-4d5a-ad69-a5f5eb821528",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "# 提取特征重要性\n",
    "cat_importances = catboost.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=cat_importances, y=features[indices])\n",
    "plt.title('CatBoost Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645c8c1-87ce-40e2-9714-ef876984fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = catboost.predict(X_test)\n",
    "cm = confusion_matrix(y_test, catboost_preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=catboost.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('CatBoost Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559fc34-c434-4f48-a5ed-bc81428dd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(catboost, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training Score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-Validation Score')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CatBoost Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c29761-3858-4a97-92e8-c0c9467de699",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = catboost.predict(X_test)\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, catboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a58a5-738b-4d65-9f09-48524e3d7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# 获取特征重要性\n",
    "xgb_importances = xgboost.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=xgb_importances, y=features[indices])\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fddade-0236-473c-ae1d-7074af9267b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds = xgboost.predict(X_test)\n",
    "cm = confusion_matrix(y_test, xgboost_preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgboost.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05731b4-416a-4579-a156-87e6e370df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds = xgboost.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgboost_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50479057-b815-438b-ae87-c8516832baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 使用 PCA 将特征降到 2 维\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# 决策边界\n",
    "xx, yy = np.meshgrid(np.linspace(X_train_pca[:, 0].min(), X_train_pca[:, 0].max(), 100),\n",
    "                     np.linspace(X_train_pca[:, 1].min(), X_train_pca[:, 1].max(), 100))\n",
    "Z = svm.decision_function(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, levels=50, cmap=\"RdBu\", alpha=0.7)\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolors='k', cmap=\"RdBu\")\n",
    "plt.title('SVM Decision Boundary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10334e93-9b06-46f0-8eae-20840742e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练集与测试集的分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 训练集分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap=\"RdBu\", edgecolors='k', alpha=0.7)\n",
    "plt.title(\"Training Set Distribution (PCA Reduced)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "\n",
    "# 测试集分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap=\"RdBu\", edgecolors='k', alpha=0.7)\n",
    "plt.title(\"Test Set Distribution (PCA Reduced)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb12919-6fa7-494b-9b8c-42a3dca58a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取预测结果\n",
    "y_pred = svm.predict(X_test_pca)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 创建混淆矩阵的可视化\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Class 0\", \"Class 1\"])\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')  # 使用蓝色调并显示为整数\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d534d-263c-4a2e-b303-03b6d4a5dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preds = svm.predict(X_test_pca)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e7b64-8e7d-480e-9fe0-e76af11ddec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.title('MLP Loss Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ce047-eb8f-4ad3-8e9b-57c599ff2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_preds = mlp.predict(X_test)\n",
    "print(\"MLP Accuracy:\", accuracy_score(y_test, mlp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954a761-9bbb-4ba9-bddc-d09290a01911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 获取预测结果\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 创建混淆矩阵的可视化\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Class 0\", \"Class 1\"])\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')  # 使用蓝色调并显示为整数\n",
    "plt.title('Confusion Matrix for MLP')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223d313-7404-42d5-a261-1e15dbdba813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# 获取学习曲线数据\n",
    "train_sizes, train_scores, valid_scores = learning_curve(mlp, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# 计算平均分数\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "valid_mean = valid_scores.mean(axis=1)\n",
    "\n",
    "# 绘制学习曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training Accuracy')\n",
    "plt.plot(train_sizes, valid_mean, label='Validation Accuracy')\n",
    "plt.title('MLP Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d96aa-ae1e-4c99-ae65-f03d084b5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型对测试集的预测概率\n",
    "y_proba = mlp.predict_proba(X_test)\n",
    "\n",
    "# 绘制预测概率的分布\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_proba[:, 1], bins=20, alpha=0.7, color='blue', label='Class 1 Probability')\n",
    "plt.hist(y_proba[:, 0], bins=20, alpha=0.7, color='red', label='Class 0 Probability')\n",
    "plt.title('Predicted Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f385ec-e090-4ba3-b49b-62026e4f456d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77aab4-8055-41aa-8ed8-092a055708ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c12ed1-3e16-4359-90a9-f6a66aae7d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
